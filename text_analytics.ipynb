{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c4bea0-40aa-48f6-980c-a92535c40cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "910bb7d3-350c-4df7-875d-391ec77bf9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words:\n",
      "['Your', 'sample', 'text', 'goes', 'here', '.']\n",
      "\n",
      "Tokenized Sentences:\n",
      "['Your sample text goes here.']\n"
     ]
    }
   ],
   "source": [
    "sample_document = \"Your sample text goes here.\"\n",
    "\n",
    "# Tokenize into words\n",
    "words = word_tokenize(sample_document)\n",
    "\n",
    "# Tokenize into sentences\n",
    "sentences = sent_tokenize(sample_document)\n",
    "\n",
    "print(\"Tokenized Words:\")\n",
    "print(words)\n",
    "print(\"\\nTokenized Sentences:\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b96bd21-8190-47e2-a370-709b3efe6ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS Tags:\n",
      "[('Your', 'PRP$'), ('sample', 'NN'), ('text', 'NN'), ('goes', 'VBZ'), ('here', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = pos_tag(words)\n",
    "\n",
    "print(\"\\nPOS Tags:\")\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5c71e0-7def-46c2-9a53-b37ace6b4b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Words (Stop Words Removed):\n",
      "['sample', 'text', 'goes', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"\\nFiltered Words (Stop Words Removed):\")\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "552263ad-af9b-4510-abee-d06ec8c468b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Words:\n",
      "['sampl', 'text', 'goe', '.']\n",
      "\n",
      "Lemmatized Words:\n",
      "['sample', 'text', 'go', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "print(\"\\nStemmed Words:\")\n",
    "print(stemmed_words)\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66372035-6aa8-4ff0-90ba-0829bbbd2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation:\n",
      "       goes      here    sample      text      your\n",
      "0  0.447214  0.447214  0.447214  0.447214  0.447214\n"
     ]
    }
   ],
   "source": [
    "documents = [sample_document]\n",
    "\n",
    "# Create the TF-IDF matrix\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame for readability\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Representation:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ce73c-e9cb-4b25-9bd8-9c252964f261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8dd37-c5ab-4895-9302-01c0e0c6cc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
